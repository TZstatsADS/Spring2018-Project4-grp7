---
title: "Project 4 main"
author: "Group7"
date: "4/16/2018"
output: html_document
---

# Memory-Based Algorithm

## Load Organized Data

We have already organized data before
```{r}
# You can check code in "MS_Organize.Rmd" in lib
# ms_train <- read.csv("../data/ms_train.csv")
# ms_test <- read.csv("../data/ms_test.csv")
# You can check code in 'movie_organize.Rmd' in lib
# movie_train <- read.csv("../data/movie_train.csv")
# movie_test <- read.csv("../data/movie_test.csv")

```


## Calculate similarity weights 

Pearson Correlation & Vector Similarity & SimRank
```{r}

# Movie

# You can check code in 'pearson_vector.Rmd' in lib
# load("../output/weight/movie_train_pearson.RData")
# load("../output/weight/movie_train_vector.RData")
# For SimRank, due to the time cose of the calculating, we simplify the data into 100*100 dimension. You can check code in 'Movie Simplify for SimRank' and 'SimRank' in lib

 
# MS

# You can check code in 'pearson_vector.Rmd' in lib
# load("../output/weight/ms_train_pearson.RData")
# load("../output/weight/ms_train_vector.RData")


```


## Select neighborhood and Prediction
```{r}
# Movie

# #movie_pearson_threshold
# neighborhood <- weight_thre(movie_train_pearson)
# movie_pearson_threshold <- movie_predict(similarity = movie_train_pearson)
# save(movie_pearson_threshold,file = "movie_pearson_threshold.RData")
# #movie_vector_threshold
# neighborhood <- weight_thre(movie_train_vector)
# movie_vector_threshold <- movie_predict(similarity = movie_train_vector)
# save(movie_vector_threshold,file = "movie_vector_threshold.RData")
# #movie_simrank_threshold
# neighborhood <- weight_thre(movie_train_simrank)
# movie_simrank_threshold <- movie_predict(train = movie_train[1:100,-1],
#                                     test = movie_test[1:100,-1],
#                                     similarity = movie_train_simrank)
# save(movie_simrank_threshold,file = "movie_simrank_threshold.RData")
# 
# #movie_pearson_bestn
# neighborhood <- weight_bestn(movie_train_pearson)
# movie_pearson_bestn <- movie_predict(similarity = movie_train_pearson)
# save(movie_pearson_bestn,file = "movie_pearson_bestn.RData")
# #movie_vector_bestn
# neighborhood <- weight_bestn(movie_train_vector)
# movie_vector_bestn <- movie_predict(similarity = movie_train_vector)
# save(movie_vector_bestn,file = "movie_vector_bestn.RData")
# #movie_simrank_bestn
# neighborhood <- weight_bestn(movie_train_simrank)
# movie_simrank_bestn <- movie_predict(train = movie_train[1:100,-1],
#                                     test = movie_test[1:100,-1],
#                                     similarity = movie_train_simrank)
# save(movie_simrank_bestn,file = "movie_simrank_bestn.RData")
# 
# #movie_pearson_comb
# neighborhood <- weight_comb(movie_train_pearson)
# movie_pearson_comb <- movie_predict(similarity = movie_train_pearson)
# save(movie_pearson_comb,file = "movie_pearson_comb.RData")
# #movie_vector_comb
# neighborhood <- weight_comb(movie_train_vector)
# movie_vector_comb <- movie_predict(similarity = movie_train_vector)
# save(movie_vector_comb,file = "movie_vector_comb.RData")
# #movie_simrank_comb
# neighborhood <- weight_comb(movie_train_simrank)
# movie_simrank_comb <- movie_predict(train = movie_train[1:100,-1],
#                                     test = movie_test[1:100,-1],
#                                     similarity = movie_train_simrank)
# save(movie_simrank_comb,file = "movie_simrank_comb.RData")


# MS
# #ms_pearson_threshold
# neighborhood <- weight_thre(ms_train_pearson)
# ms_pearson_threshold <- ms_predict(train = ms_train[,-1],
#                       test = ms_test[,-1],
#                      similarity = ms_train_pearson,
#                      neighborhood = neighborhood)
# save(ms_pearson_threshold,file = "ms_pearson_threshold.RData")
# #ms_vector_threshold
# neighborhood <- weight_thre(ms_train_vector)
# ms_vector_threshold <- ms_predict(train = ms_train[,-1],
#                      test = ms_test[,-1],
#                      similarity = ms_train_vector,
#                      neighborhood = neighborhood)
# save(ms_vector_threshold,file = "ms_vector_threshold.RData")
# #ms_pearson_bestn
# neighborhood <- weight_bestn(ms_train_pearson)
# ms_pearson_bestn <- ms_predict(train = ms_train[,-1],
#                      test = ms_test[,-1],
#                      similarity = ms_train_pearson,
#                      neighborhood = neighborhood)
# save(ms_pearson_bestn,file = "ms_pearson_bestn.RData")
# #movie_vector_bestn
# neighborhood <- weight_bestn(ms_train_vector)
# ms_vector_bestn <- ms_predict(train = ms_train[,-1],
#                      test = ms_test[,-1],
#                      similarity = ms_train_vector,
#                      neighborhood = neighborhood)
# save(ms_vector_bestn,file = "ms_vector_bestn.RData")
# #ms_pearson_comb
# neighborhood <- weight_comb(ms_train_pearson)
# ms_pearson_comb <- ms_predict(train = ms_train[,-1],
#                      test = ms_test[,-1],
#                      similarity = ms_train_pearson,
#                      neighborhood = neighborhood)
# save(ms_pearson_comb,file = "ms_pearson_comb.RData")
# #movie_vector_comb
# neighborhood <- weight_comb(ms_train_vector)
# ms_vector_comb <- ms_predict(train = ms_train[,-1],
#                      test = ms_test[,-1],
#                      similarity = ms_train_vector,
#                      neighborhood = neighborhood)
# save(ms_vector_comb,file = "ms_vector_comb.RData")
```

## Evaluation for MS
```{r}
R<-function(predict,true,d=0,alpha=10){
  r<-rep(0,nrow(true))
  r_max<-rep(0,nrow(true))
  
  for(a in 1:nrow(true)){
    
    r[a]<-sort(r[a],decreasing = T)
    true[a,]<-sort(true[a,],decreasing = T)
    
    for(j in 1:ncol(true)){
      
      r[a]<-r[a]+max(predict[a,]-d,0)/2^((j-1)/(alpha-1))
      r_max[a]<-r_max[a]+sum(max(true[a,]-d,0)/2^((j-1)/(alpha-1)))
      
    }
  }
  
  rs<-100*sum(r)/sum(r_max)
  return(rs)
}

# load("../output/memory_based_predict/ms/ms_pearson_bestn.RData")
# load("../output/memory_based_predict/ms/ms_pearson_threhold.RData")
# load("../output/memory_based_predict/ms/ms_pearson_comb.RData")
# load("../output/memory_based_predict/ms/ms_vector_bestn.RData")
# load("../output/memory_based_predict/ms/ms_vector_threhold.RData")
# load("../output/memory_based_predict/ms/ms_vector_comb.RData")

# R_ms_pearson_bestn <- R(ms_pearson_bestn, ms_test, 0, 10)
# R_ms_pearson_bestn
# R_ms_pearson_threhold <- R(ms_pearson_threhold, ms_test, 0, 10)
# R_ms_pearson_threhold
# R_ms_pearson_comb <- R(ms_pearson_comb, ms_test, 0, 10)
# R_ms_pearson_comb
# R_ms_vector_bestn <- R(ms_vector_bestn, ms_test, 0, 10)
# R_ms_vector_bestn
# R_ms_vector_threhold <- R(ms_vector_threhold, ms_test, 0, 10)
# R_ms_vector_threhold
# R_ms_vector_comb <- R(ms_vector_comb, ms_test, 0, 10)
# R_ms_vector_comb
```


## Evaluation for Movie
```{r}
options(warn = -1)

# # load data
# setwd("~/GitHub/Spring2018-Project4-grp7/data")
# test <- read.csv("movie_test.csv")
# test <- test[,-1]
# test2 <- test[1:100,]

# setwd("~/GitHub/Spring2018-Project4-grp7/output/memory_based_predict/movie")
# load("movie_pearson_threshold.Rdata")
# pred_pear_thr <- movie_pearson_threshold
# load("movie_vector_threshold.Rdata")
# pred_vec_thr <- movie_vector_threshold
# load("movie_simrank_threshold.Rdata")
# pred_sim_thr <- movie_simrank_threshold

# load("movie_pearson_bestn.Rdata")
# pred_pear_bn <- movie_pearson_bestn
# load("movie_vector_bestn.Rdata")
# pred_vec_bn <- movie_vector_bestn
# load("movie_simrank_bestn.Rdata")
# pred_sim_bn <- movie_simrank_bestn

# load("movie_pearson_comb.Rdata")
# pred_pear_cb <- movie_pearson_comb
# load("movie_vector_comb.Rdata")
# pred_vec_cb <- movie_vector_comb
# load("movie_simrank_comb.Rdata")
# pred_sim_cb <- movie_simrank_comb


## MAE

#function
mae <- function(pred, test){
  mae <- mean(abs(pred - test), na.rm = T)
  return(mae)
}

#output
mae(pred_pear_thr, as.matrix(test))
mae(pred_vec_thr, as.matrix(test))
mae(pred_sim_thr, as.matrix(test2))
mae(pred_pear_bn, as.matrix(test))
mae(pred_vec_bn, as.matrix(test))
mae(pred_sim_bn, as.matrix(test2))
mae(pred_pear_cb, as.matrix(test))
mae(pred_vec_cb, as.matrix(test))
mae(pred_sim_cb, as.matrix(test2))


## ROC

library("pROC")

#function
# remove NA value
test_v_0 <- as.vector(as.matrix(test))
test_v_1 <- as.vector(as.matrix(test2))
idx0 <- which(is.na(test_v_0)==T)
idx1 <- which(is.na(test_v_1)==T)

auc <- function(Pred,Test,Idx){
  pred_v <- as.vector(Pred)
  idx2 <- which(is.na(pred_v)==T)
  idx <- union(Idx,idx2)
  pred_v <- pred_v[setdiff(1:length(Test),idx)]
  test_v <- Test[setdiff(1:length(Test),idx)]
  Roc <- roc(test_v,pred_v)
  return(Roc$auc)
}

curve <- function(Pred,Test,Idx){
  pred_v <- as.vector(Pred)
  idx2 <- which(is.na(pred_v)==T)
  idx <- union(Idx,idx2)
  pred_v <- pred_v[setdiff(1:length(Test),idx)]
  test_v <- Test[setdiff(1:length(Test),idx)]
  Roc <- roc(test_v,pred_v)
  curve <- plot(Roc) 
  return(curve)
}


#output
 
auc(pred_pear_thr,test_v_0,idx0)
curve(pred_pear_thr,test_v_0,idx0)
auc(pred_vec_thr,test_v_0,idx0)
curve(pred_vec_thr,test_v_0,idx0)
auc(pred_sim_thr,test_v_1,idx1)
curve(pred_sim_thr,test_v_1,idx1) 

auc(pred_pear_bn,test_v_0,idx0)
curve(pred_pear_bn,test_v_0,idx0)
auc(pred_vec_bn,test_v_0,idx0)
curve(pred_vec_bn,test_v_0,idx0)
auc(pred_sim_bn,test_v_1,idx1)
curve(pred_sim_bn,test_v_1,idx1) 

auc(pred_pear_cb,test_v_0,idx0)
curve(pred_pear_cb,test_v_0,idx0)
auc(pred_vec_cb,test_v_0,idx0)
curve(pred_vec_cb,test_v_0,idx0)
auc(pred_sim_cb,test_v_1,idx1)
curve(pred_sim_cb,test_v_1,idx1)
```


# Model-Based Algorithm
---
title: "Untitled"
output: html_document
---

# Load processed datasets
```{r}
load("../data/MS_sample/train1.RData")
load("../data/MS_sample/test1.RData")
```

# Model-based Algorithm

### EM algorithm 

We implement cluster model to make predictions about ratings. In the model-based algorithm, the ratings each user gives to a specific item is a random variable.  We use Bayesian Mixture to model this random variable by incorporating the information from the available ratings. We assume that each user belongs to a cluster c, where the number of clusters is determined by cross validation. 

EM-algorithm is used to iteratively update the "soft assignment" - the probability that each user belongs to a specific cluster, and the parameters - the relative cluster size and the probability that user i gives item j a rating of k given that user i belongs to cluster c.

Here is the EM-algorithm part:

```{r}

N <- dim(train1)[1]
D <- dim(train1)[2]
N2 <- dim(test1)[1]

I_1 = list() # list of papers voted 1 by each user 
I_1[[1]] = as.numeric(unlist(which(train1[1,] == 1)))
for (i in 2:N) {
  k = as.numeric(unlist(which(train1[i,] == 1)))
  I_1 = c(I_1,list(k))
}

I_0 = list() # list of papers voted 0 by each user 
I_0[[1]] = as.numeric(unlist(which(train1[1,] == 0)))
for (i in 2:N) {
  k = as.numeric(unlist(which(train1[i,] == 0)))
  I_0 = c(I_0,list(k))
}

J_1 = list() # list of users who vote 1 each paper
J_1[[1]] = as.numeric(unlist(which(train1[,1] == 1)))
for (i in 2:D) {
  k = as.numeric(unlist(which(train1[,i] == 1)))
  J_1 = c(J_1,list(k))
}

J_0 = list() # list of users who vote 0 each paper
J_0[[1]] = as.numeric(unlist(which(train1[,1] == 0)))
for (i in 2:D) {
  k = as.numeric(unlist(which(train1[,i] == 0)))
  J_0 = c(J_0,list(k))
}

multinomialEM <- function(data, C, t = 1*10^-6){
  change_1 <- 1 # Measures change in centroids
  change_0 <- 1
  #cp <- matrix(1/C, nrow = N, ncol = C)
  cp <- runif(C)
  cp = cp/sum(cp)
  gamma_1 = matrix(runif(C*D), nrow = C, ncol = D)
  gamma_0 = 1-gamma_1
  A <- matrix (0, N, C) # responsibilities pi
  Phi <- matrix(0, N, C)

  while(change_1 > t | change_0 > t){
    # E step
    for (k in 1:C) {
      for (i in 1:N) {
        Phi[i,k] = prod(gamma_0[k,I_0[[i]]]) * prod(gamma_1[k,I_1[[i]]]) * cp[k]
      }
    }
    
    A<-Phi/rowSums(Phi)
    
    #for (i in 1:N) {
    #  A[i, ] <- Phi[i, ]/sum(Phi[i, ]) # responsibilities pi
    #}
    
    # M step
 
    cp = colSums(A)/N
    
    
    gamma_1_old = gamma_1
    gamma_0_old = gamma_0
    
    for (k in 1:C) {
      for (j in 1:D) {
        gamma_1[k,j] = sum(A[J_1[[j]],k])/sum(A[,k])
        gamma_0[k,j] = sum(A[J_0[[j]],k])/sum(A[,k])
      }
    }
    
    change_1 = norm(gamma_1_old - gamma_1, type = "O")
    change_0 = norm(gamma_0_old - gamma_0, type = "O")
  }
  return(result = list(cp, gamma_1, gamma_0, A))

}

```

### Predict after training
```{r}
# Prediction
predictCF <- function(data_test = test1, param){
  B = list() # list of papers needed to predict from each user
  B[[1]] = as.numeric(unlist(which(data_test[1,] == 1)))
  for (i in 2:N2) {
    k = as.numeric((which(data_test[i,] == 1)))
    B = c(B,list(k))
  }

  gamma1 = param[[2]]
  A = param[[4]]
  expect.mat = matrix(0, ncol = ncol(data_test), nrow = nrow(data_test))
  colnames(expect.mat) = colnames(data_test)
  for (i in 1:length(B)) {
    for (j in 1:length(B[[i]])) {
      if(length(B[[i]]) == 0){
        expect.mat[i,B[[i]][j]] = NA
    }
      else{
        expect.mat[i,B[[i]][j]] = (A[i,] %*% gamma1[,B[[i]]])[j]
    }

   }
 }

  return(expect.mat)
}

```

### Use CV to pick the best cluster number and use ranked scoring for evaluation
```{r}
# Separate the training data into two parts--training set and validation set
  
   training_data = train1
   validation_data = matrix(0,nrow = nrow(train1), ncol = ncol(train1))
   rownames(validation_data)<-rownames(training_data)
   colnames(validation_data)<-colnames(training_data)
   set.seed(2249)
   index<-c()
   
    for (i in 1:nrow(training_data)) {
      
      index<-as.numeric(unlist(which(train1[i,] == 1)))
      v_index <- sample(index, round(length(index) * 0.25))
      training_data[i,v_index]<-0
      validation_data[i,v_index]<-1
      
    }

# Caculate the accuracy rate using ranked scoring
   
R<-function(predict,true,d=0.05,alpha=10){ # We ran a set of experiments using a halife of 10 items
                                        # and found little sensitivity of results.
  
  r<-rep(0,nrow(true))
  r_max<-rep(0,nrow(true))
  
  for(a in 1:nrow(true)){
    
    r[a]<-sort(r[a],decreasing = T)
    true[a,]<-sort(true[a,],decreasing = T)
    
    for(j in 1:ncol(true)){
      
      r[a]<-r[a]+max(predict[a,]-d,0)/2^((j-1)/(alpha-1))
      r_max[a]<-r_max[a]+sum(max(true[a,]-d,0)/2^((j-1)/(alpha-1)))
      
    }
  }
  
  rs<-100*sum(r)/sum(r_max)
  return(rs)
}

# Choose the best cluster number
nC = 10:25 

cv.accuracy<- c()
for (i in 1:length(nC)) {
 
  coef = multinomialEM(training_data, nC[i])
  EM_predict = predictCF(validation_data, coef)
  cv.accuracy[i] <- R(EM_predict,validation_data,d=0.05,alpha=10)
  
  }

cluster <- data.frame(nC,cv.accuracy)
ggplot(cluster, aes(x=nC, y=cv.accuracy)) + geom_line(col = 'red') +geom_point( size=4, shape=21, fill="white") +labs( x = 'Cluster Number',y = 'Rank Score')+ ggtitle('RANK SCORE FOR CLUSTER MODEL')


```

### Use the best parameter to calculate the accuracy
```{r}
# Test Error
best.C = 24
best.coef <- multinomialEM(train1, C = best.C)
best.pred <- predictCF(test1, best.coef)
accuracy1 <-sum(best.pred)/sum(test1)  
#C=14 0.20367 
#C=24 0.2044247
accuracy2<-R(best.pred,test1,d=0,alpha=10)
#C=24 39.33172
#C=14 38.6151

```




